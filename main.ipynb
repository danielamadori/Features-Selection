{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3a6088",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to Feature Selection Project\n",
    "\n",
    "This Jupyter notebook is part of a project focused on exploring various feature selection techniques to enhance the performance of machine learning models. The project uses the \"Breast Cancer Wisconsin (Diagnostic)\" dataset, applying methods like Mutual Information Feature Selection (MIFS), Correlation Feature Selection (CFS), and Sequential Forward Selection (SFS) among others, to identify the most significant features for accurate predictions.\n",
    "\n",
    "The goal of this notebook is to provide a comprehensive analysis of these feature selection techniques, compare their effectiveness, and understand their impact on model performance. By the end of this notebook, we should have a clear understanding of which features are most important and why, as well as insights into the strengths and limitations of each feature selection method used.\n",
    "\n",
    "This project is licensed under the MIT License - see the LICENSE file for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b7aa3da5-85db-469f-8ddf-7a6195e6571d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:07:19.441981300Z",
     "start_time": "2024-02-18T23:07:19.159042500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   radius1             569 non-null    float64\n",
      " 1   texture1            569 non-null    float64\n",
      " 2   perimeter1          569 non-null    float64\n",
      " 3   area1               569 non-null    float64\n",
      " 4   smoothness1         569 non-null    float64\n",
      " 5   compactness1        569 non-null    float64\n",
      " 6   concavity1          569 non-null    float64\n",
      " 7   concave_points1     569 non-null    float64\n",
      " 8   symmetry1           569 non-null    float64\n",
      " 9   fractal_dimension1  569 non-null    float64\n",
      " 10  radius2             569 non-null    float64\n",
      " 11  texture2            569 non-null    float64\n",
      " 12  perimeter2          569 non-null    float64\n",
      " 13  area2               569 non-null    float64\n",
      " 14  smoothness2         569 non-null    float64\n",
      " 15  compactness2        569 non-null    float64\n",
      " 16  concavity2          569 non-null    float64\n",
      " 17  concave_points2     569 non-null    float64\n",
      " 18  symmetry2           569 non-null    float64\n",
      " 19  fractal_dimension2  569 non-null    float64\n",
      " 20  radius3             569 non-null    float64\n",
      " 21  texture3            569 non-null    float64\n",
      " 22  perimeter3          569 non-null    float64\n",
      " 23  area3               569 non-null    float64\n",
      " 24  smoothness3         569 non-null    float64\n",
      " 25  compactness3        569 non-null    float64\n",
      " 26  concavity3          569 non-null    float64\n",
      " 27  concave_points3     569 non-null    float64\n",
      " 28  symmetry3           569 non-null    float64\n",
      " 29  fractal_dimension3  569 non-null    float64\n",
      " 30  target              569 non-null    object \n",
      "dtypes: float64(30), object(1)\n",
      "memory usage: 137.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from printScore import *\n",
    "import pandas as pd\n",
    "\n",
    "path = 'dataset/'\n",
    "filename = 'breast-cancer-wisconsin.csv'\n",
    "\n",
    "try:\n",
    "\tdf = pd.read_csv(path + filename)\n",
    "except FileNotFoundError:\n",
    "\t# fetch dataset \n",
    "\tbreast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "\t\n",
    "\t# data (as pandas dataframes) \n",
    "\tX = breast_cancer_wisconsin_diagnostic.data.features\n",
    "\ty = breast_cancer_wisconsin_diagnostic.data.targets\n",
    "\t\n",
    "\t# Create a Pandas DataFrame with the features and the target\n",
    "\tdf = X.copy()\n",
    "\tdf['target'] = y.copy()\n",
    "\tdf.to_csv(path + filename, index=False)\n",
    "\t\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d7cba7bb4b4a1bf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:07:19.714590600Z",
     "start_time": "2024-02-18T23:07:19.446295600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     radius1  texture1  perimeter1   area1  smoothness1  compactness1  \\\n0      17.99     10.38      122.80  1001.0      0.11840       0.27760   \n1      20.57     17.77      132.90  1326.0      0.08474       0.07864   \n2      19.69     21.25      130.00  1203.0      0.10960       0.15990   \n3      11.42     20.38       77.58   386.1      0.14250       0.28390   \n4      20.29     14.34      135.10  1297.0      0.10030       0.13280   \n..       ...       ...         ...     ...          ...           ...   \n564    21.56     22.39      142.00  1479.0      0.11100       0.11590   \n565    20.13     28.25      131.20  1261.0      0.09780       0.10340   \n566    16.60     28.08      108.30   858.1      0.08455       0.10230   \n567    20.60     29.33      140.10  1265.0      0.11780       0.27700   \n568     7.76     24.54       47.92   181.0      0.05263       0.04362   \n\n     concavity1  concave_points1  symmetry1  fractal_dimension1  ...  \\\n0       0.30010          0.14710     0.2419             0.07871  ...   \n1       0.08690          0.07017     0.1812             0.05667  ...   \n2       0.19740          0.12790     0.2069             0.05999  ...   \n3       0.24140          0.10520     0.2597             0.09744  ...   \n4       0.19800          0.10430     0.1809             0.05883  ...   \n..          ...              ...        ...                 ...  ...   \n564     0.24390          0.13890     0.1726             0.05623  ...   \n565     0.14400          0.09791     0.1752             0.05533  ...   \n566     0.09251          0.05302     0.1590             0.05648  ...   \n567     0.35140          0.15200     0.2397             0.07016  ...   \n568     0.00000          0.00000     0.1587             0.05884  ...   \n\n     texture3  perimeter3   area3  smoothness3  compactness3  concavity3  \\\n0       17.33      184.60  2019.0      0.16220       0.66560      0.7119   \n1       23.41      158.80  1956.0      0.12380       0.18660      0.2416   \n2       25.53      152.50  1709.0      0.14440       0.42450      0.4504   \n3       26.50       98.87   567.7      0.20980       0.86630      0.6869   \n4       16.67      152.20  1575.0      0.13740       0.20500      0.4000   \n..        ...         ...     ...          ...           ...         ...   \n564     26.40      166.10  2027.0      0.14100       0.21130      0.4107   \n565     38.25      155.00  1731.0      0.11660       0.19220      0.3215   \n566     34.12      126.70  1124.0      0.11390       0.30940      0.3403   \n567     39.42      184.60  1821.0      0.16500       0.86810      0.9387   \n568     30.37       59.16   268.6      0.08996       0.06444      0.0000   \n\n     concave_points3  symmetry3  fractal_dimension3  target  \n0             0.2654     0.4601             0.11890     1.0  \n1             0.1860     0.2750             0.08902     1.0  \n2             0.2430     0.3613             0.08758     1.0  \n3             0.2575     0.6638             0.17300     1.0  \n4             0.1625     0.2364             0.07678     1.0  \n..               ...        ...                 ...     ...  \n564           0.2216     0.2060             0.07115     1.0  \n565           0.1628     0.2572             0.06637     1.0  \n566           0.1418     0.2218             0.07820     1.0  \n567           0.2650     0.4087             0.12400     1.0  \n568           0.0000     0.2871             0.07039     0.0  \n\n[569 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius1</th>\n      <th>texture1</th>\n      <th>perimeter1</th>\n      <th>area1</th>\n      <th>smoothness1</th>\n      <th>compactness1</th>\n      <th>concavity1</th>\n      <th>concave_points1</th>\n      <th>symmetry1</th>\n      <th>fractal_dimension1</th>\n      <th>...</th>\n      <th>texture3</th>\n      <th>perimeter3</th>\n      <th>area3</th>\n      <th>smoothness3</th>\n      <th>compactness3</th>\n      <th>concavity3</th>\n      <th>concave_points3</th>\n      <th>symmetry3</th>\n      <th>fractal_dimension3</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.16220</td>\n      <td>0.66560</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.12380</td>\n      <td>0.18660</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.14440</td>\n      <td>0.42450</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.20980</td>\n      <td>0.86630</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.13740</td>\n      <td>0.20500</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>21.56</td>\n      <td>22.39</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>0.11100</td>\n      <td>0.11590</td>\n      <td>0.24390</td>\n      <td>0.13890</td>\n      <td>0.1726</td>\n      <td>0.05623</td>\n      <td>...</td>\n      <td>26.40</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n      <td>0.14100</td>\n      <td>0.21130</td>\n      <td>0.4107</td>\n      <td>0.2216</td>\n      <td>0.2060</td>\n      <td>0.07115</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>20.13</td>\n      <td>28.25</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>0.09780</td>\n      <td>0.10340</td>\n      <td>0.14400</td>\n      <td>0.09791</td>\n      <td>0.1752</td>\n      <td>0.05533</td>\n      <td>...</td>\n      <td>38.25</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n      <td>0.11660</td>\n      <td>0.19220</td>\n      <td>0.3215</td>\n      <td>0.1628</td>\n      <td>0.2572</td>\n      <td>0.06637</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>16.60</td>\n      <td>28.08</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>0.08455</td>\n      <td>0.10230</td>\n      <td>0.09251</td>\n      <td>0.05302</td>\n      <td>0.1590</td>\n      <td>0.05648</td>\n      <td>...</td>\n      <td>34.12</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n      <td>0.11390</td>\n      <td>0.30940</td>\n      <td>0.3403</td>\n      <td>0.1418</td>\n      <td>0.2218</td>\n      <td>0.07820</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>20.60</td>\n      <td>29.33</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.11780</td>\n      <td>0.27700</td>\n      <td>0.35140</td>\n      <td>0.15200</td>\n      <td>0.2397</td>\n      <td>0.07016</td>\n      <td>...</td>\n      <td>39.42</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.16500</td>\n      <td>0.86810</td>\n      <td>0.9387</td>\n      <td>0.2650</td>\n      <td>0.4087</td>\n      <td>0.12400</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>7.76</td>\n      <td>24.54</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>0.05263</td>\n      <td>0.04362</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.1587</td>\n      <td>0.05884</td>\n      <td>...</td>\n      <td>30.37</td>\n      <td>59.16</td>\n      <td>268.6</td>\n      <td>0.08996</td>\n      <td>0.06444</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2871</td>\n      <td>0.07039</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows × 31 columns</p>\n</div>"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(df['target'].values.reshape(-1, 1))\n",
    "df['target'] = enc.transform(df['target'].values.reshape(-1, 1))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd044ef6454a08c",
   "metadata": {},
   "source": [
    "# Discretization with ChiMerge\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Data Preparation**: Begin with continuous numerical data, and sort it in ascending order.\n",
    "\n",
    "2. **Initial Binning**: Create initial bins, typically with a fixed number of data points or fixed width.\n",
    "\n",
    "3. **Calculate Chi-Squared Statistic**: Calculate the chi-squared statistic for each pair of adjacent bins using observed and expected frequencies.\n",
    "\n",
    "4. **Chi-Squared Test**: Apply a chi-squared test to decide whether to merge adjacent bins or keep them separate.\n",
    "\n",
    "5. **Iterate**: Continue merging adjacent bins with chi-squared statistics below the threshold until you reach the desired number of bins or all chi-squared statistics exceed the threshold.\n",
    "\n",
    "6. **Final Binning**: The boundaries of the bins represent the discrete intervals.\n",
    "\n",
    "7. **Discretization**: Replace the continuous data with bin labels to indicate which bin each data point belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9ffb5dfa80886243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:07:19.897297800Z",
     "start_time": "2024-02-18T23:07:19.512219900Z"
    }
   },
   "outputs": [],
   "source": [
    "from scorecardbundle.feature_discretization import ChiMerge as cm\n",
    "from scorecardbundle.feature_encoding import WOE as woe\n",
    "\n",
    "def chiMerge(df, X_features, y_features, max_intervals=10, min_intervals=2, decimal=None):\n",
    "\ttrans_cm = cm.ChiMerge(max_intervals=max_intervals, min_intervals=min_intervals, decimal=decimal, output_dataframe=True)\n",
    "\n",
    "\tencoder = woe.WOE_Encoder()\n",
    "\tdiscreteDf = pd.DataFrame(\n",
    "\t\tencoder.fit_transform(trans_cm.fit_transform(df[X_features], df[y_features]), df[y_features]),\n",
    "\t\tcolumns=X_features, index=df.index\n",
    "\t)\n",
    "\tdiscreteDf[y_features] = df[y_features]\n",
    "\n",
    "\tuniqueValuesNumber = {feature : len(trans_cm.boundaries_[feature]) for feature in X_features}\n",
    "\t\n",
    "\treturn discreteDf, uniqueValuesNumber, trans_cm.boundaries_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2506a51b3490d55b",
   "metadata": {},
   "source": [
    "# Entropy \n",
    "![H(c) = - Sum(P(c) * log2(P(c)))](images/entropy.PNG)\n",
    "# Joint Entropy\n",
    "![H(C;F) = - Sum(P(c,f) * log2(P(c,f)))](images/jointEntropy.PNG)\n",
    "# Conditional Entropy\n",
    "![H(C|F) = H(C,F) - H(F)](images/conditionalEntropy.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "938b9f4eb2dcd322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:07:19.912521600Z",
     "start_time": "2024-02-18T23:07:19.518909800Z"
    }
   },
   "outputs": [],
   "source": [
    "from mathFunctions import probability, jointProbabilities\n",
    "\n",
    "# Cache Dictionary\n",
    "entropyCache, jointEntropyCache = {}, {}\n",
    "\n",
    "# H(c) = - Sum(P(c) * log2(P(c)))\n",
    "def entropy(discreteDf, X_feature):\n",
    "\tif X_feature in entropyCache:\n",
    "\t\treturn entropyCache[X_feature]\n",
    "\t\n",
    "\tprob = probability(discreteDf[X_feature].values)\n",
    "\tentropyCache[X_feature] = -np.sum(prob * np.log2(prob))\n",
    "\n",
    "\treturn entropyCache[X_feature]\n",
    "\n",
    "# H(C;F) = - Sum(P(c,f) * log2(P(c,f)))\n",
    "def jointEntropy(discreteDf, X_feature, y_feature):\n",
    "\t# Create a key that doesn't depend on the order of the features\n",
    "\ttmp0, tmp1 = sorted([X_feature, y_feature]) # is a symmetric function\n",
    "\tkey = f\"{tmp0}-{tmp1}\"\n",
    "\t\n",
    "\tif key in jointEntropyCache:\n",
    "\t\treturn jointEntropyCache[key]\n",
    "\t\n",
    "\tjp= jointProbabilities(discreteDf[X_feature].values, discreteDf[y_feature].values)\n",
    "\tjp = jp[jp > 0]\n",
    "\tjointEntropyCache[key] = - np.sum(jp * np.log2(jp))\n",
    "\t\n",
    "\treturn jointEntropyCache[key]\n",
    "\n",
    "# H(C|F) = H(C,F) - H(F)\n",
    "def conditionalEntropy(discreteDf, X_feature, y_feature):\n",
    "\treturn jointEntropy(discreteDf, X_feature, y_feature) - entropy(discreteDf, y_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d841d1a4eed59a1",
   "metadata": {},
   "source": [
    "# Mutual Information\n",
    "![mutualInformation](images/mutualInformation.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b510fc340fe67f42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:07:20.513210600Z",
     "start_time": "2024-02-18T23:07:19.860726900Z"
    }
   },
   "outputs": [],
   "source": [
    "# I_(f;c) = H(f) - H(f|c) Mutual Information function\n",
    "def mutual_information(discreteDf, X_feature, y_feature):\n",
    "\tmi = entropy(discreteDf, X_feature) - conditionalEntropy(discreteDf, X_feature, y_feature)\n",
    "\t\n",
    "\tif mi < 0:\n",
    "\t\tprint(\"Mutual Information error: \")\n",
    "\t\tprint(f\"I({X_feature};{y_feature}) = H({X_feature})-H({X_feature}, {y_feature}) = {entropy(discreteDf, X_feature):.3f} - {conditionalEntropy(discreteDf, X_feature, y_feature):.3f} = {mi:.5f}\")\n",
    "\t\n",
    "\treturn mi\n",
    "\n",
    "#print(\"Finish: \", mutual_information(discreteDf, discreteDf.columns.tolist(), discreteDf.columns[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24107d551f302ed7",
   "metadata": {},
   "source": [
    "# Evaluation Function: Mutual Information Feature Selection (MIFS)\n",
    "\n",
    "![MIFS_formula](images/MIFS_formula.PNG)\n",
    "\n",
    "Where:\n",
    "- f: feature in remaining features\n",
    "- S: all the selected features\n",
    "- C: the target feature (class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4513e3af",
   "metadata": {},
   "source": [
    "**Reference**: Roberto Battiti, \"Using Mutual Information for Selecting Features in Supervised Neural Net Learning\", IEEE Transactions on Neural Networks, August 1994. DOI: [10.1109/72.298224](https://doi.org/10.1109/72.298224)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "827beecb61ef51db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:07:20.933497100Z",
     "start_time": "2024-02-18T23:07:20.463277900Z"
    }
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "#from ipyparallel import Client\n",
    "#c = Client(profile='default')\n",
    "\n",
    "def mifs(discreteDf, selectedFeatures, feature, _class, beta=0.5):\n",
    "\tmiFeatureClass = mutual_information(df, _class, feature) #I_(C;f) = H(C) - H(C|f)\n",
    "\n",
    "\t# I_(f;S) = Sum(I_(f;s)) for each s in S\n",
    "\tif not isinstance(selectedFeatures, list): # Check if y_features is a list\n",
    "\t\tselectedFeatures = [selectedFeatures]\n",
    "\n",
    "\tsum_mi_SelectedFeatures = 0\n",
    "\twith concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor: # Use ThreadPoolExecutor to parallelize the calculations\n",
    "\t\t# Submit tasks for each combination of X_feature and y_feature\n",
    "\t\tfutures = [executor.submit(mutual_information, discreteDf, feature, selectedFeature) for selectedFeature in selectedFeatures]\n",
    "\tfor future in concurrent.futures.as_completed(futures): # Gather the results\n",
    "\t\tsum_mi_SelectedFeatures += future.result()\n",
    "\t#print(f\"\\nI_(f;S) = Sum(I_(f;s)) = {sum}\\n-F = {feature}\\n-S = {selectedFeatures}\\n\")\n",
    "\t\n",
    "\t# I_(C;f) - Beta * (Som(#I_(f;s)) for each s in S)\n",
    "\tresult = miFeatureClass - beta * sum_mi_SelectedFeatures\n",
    "\t#print(f\"I({_class};{feature})-Beta*(Som(I_({feature};s)) for each s in S) ={miFeatureClass:.3} - {beta} * {sum_mi_SelectedFeatures:.3f} = {result:.5f}\")\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573cb7069ad60e91",
   "metadata": {},
   "source": [
    "# Evaluation Function: Correlation Feature Selection (CFS)\n",
    "\n",
    "CFS is a filter-based method that evaluates the worth of a subset of features by considering the individual predictive ability of each feature along with the degree of redundancy between them.\n",
    "\n",
    "![CSF_formula](images/CSF_formula.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "88c530fe2b1ec4ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:07:21.307689200Z",
     "start_time": "2024-02-18T23:07:20.804154400Z"
    }
   },
   "outputs": [],
   "source": [
    "def cfs(df, attributes, _class):\n",
    "\tk = len(attributes)\n",
    "\n",
    "\tavgCorrAttributeClass = 0\n",
    "\tavgCorrAttributeAttribute = 0\n",
    "\tfor attribute in attributes:\n",
    "\t\t# compute the average correlation between the attributes and the class\n",
    "\t\tavgCorrAttributeClass += np.abs(df[attribute].corr(df[_class]))\n",
    "\t\t# compute the average correlation between the attributes\n",
    "\t\tremainingAttributes = attributes.copy()\n",
    "\t\tremainingAttributes.remove(attribute)\n",
    "\t\tfor attribute2 in remainingAttributes:\n",
    "\t\t\tavgCorrAttributeAttribute += np.abs(df[attribute].corr(df[attribute2]))\n",
    "\n",
    "\tavgCorrAttributeClass =  avgCorrAttributeClass / k\n",
    "\tavgCorrAttributeAttribute = avgCorrAttributeAttribute / (k * k)\n",
    "\n",
    "\t# compute the score of the testFeature\n",
    "\treturn (k * avgCorrAttributeClass) / np.sqrt(k + k * (k - 1) * avgCorrAttributeAttribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e6edab3bc22fe9",
   "metadata": {},
   "source": [
    "## Sequential Forward Selection (SFS)\n",
    "\n",
    "The SFS algorithm is a feature selection method that starts with a single attribute and incrementally adds attributes until the full set of attributes is reached. It is particularly effective when the optimal subset has only a few attributes. The process involves evaluating a large number of states initially, but as it progresses, the region examined by SFS becomes narrower since most of the attributes have already been selected.\n",
    "\n",
    "![SFS](images/SFS.PNG)\n",
    "\n",
    "## Implementation of the SFS Algorithm\n",
    "\n",
    "In the following implementation of the SFS algorithm, we begin with a set of features, which can be either empty or contain initial attributes, and a list of remaining features, which includes all features except those already selected and the target feature. The algorithm operates through a series of iterations:\n",
    "\n",
    "1. Compute the score of each remaining feature considering the selected features and the target feature.\n",
    "2. Select the feature with the best score.\n",
    "3. Add the selected feature to the list of selected features.\n",
    "4. Remove the selected feature from the list of remaining features.\n",
    "\n",
    "This process is repeated until the maximum number of iterations is reached or until there are no more remaining features to select from.\n",
    "\n",
    "### Evaluation Functions for Feature Score\n",
    "\n",
    "The score of each feature is computed using one of the following evaluation functions:\n",
    "\n",
    "- Variance\n",
    "- Correlation\n",
    "- Correlation Feature Selection (CFS)\n",
    "- Mutual Information Feature Selection (MIFS)\n",
    "\n",
    "If multiple evaluation functions are given to the function, the score is based on the metrics order of priority given by the order of the metrics in the metrics list, so if the first score is the same for two features, the second score is used to determine the best feature and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7b77cc68459f6575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:07:21.737931300Z",
     "start_time": "2024-02-18T23:07:21.358039200Z"
    }
   },
   "outputs": [],
   "source": [
    "from metrics import checkMetrics, createFeatureScore, compareFeatureScore\n",
    "from utils import mifs_caching_init, mifs_caching_flush\n",
    "\n",
    "allowedMetrics = ['variance', 'correlation', 'cfs', 'mifs']\n",
    "\n",
    "# MIFS caching\n",
    "discreteDf, entropyCache, jointEntropyCache, discreteDf_filename, entropyFilename, jointEntropyFilename = mifs_caching_init(path, filename, 'discrete.csv', 'entropy.csv', 'joint_entropy.csv')\n",
    "\n",
    "def selection_sfs(df, selectedFeatures, remainingFeatures, target, metrics, maxIteration=np.inf, discreteDf=None, beta=0.5):\n",
    "\tmetrics = checkMetrics(metrics, allowedMetrics)\n",
    "\n",
    "\t# Create the discrete data frame if needed\n",
    "\tmifs_cache = discreteDf is not None\n",
    "\tif allowedMetrics[3] in metrics and discreteDf is None:\n",
    "\t\tprint(\"Warning: mifs cache not enabled\")\n",
    "\t\tdiscreteDf, uniqueValuesNumber, featuresBoundaries = chiMerge(df, df.columns[:-1].tolist(), df.columns[-1], max_intervals=100, min_intervals=2)\n",
    "\t\tdiscreteDf.to_csv(path + discreteDf_filename, index=False)\n",
    "\t\tglobal entropyCache, jointEntropyCache\n",
    "\t\tentropyCache, jointEntropyCache = {}, {} # Cleaning Cache\n",
    "\t\t\n",
    "\t\t#print(\"Features Boundaries:\\n\", featuresBoundaries)\n",
    "\t\t#print(\"Features unique values:\\n\", pd.DataFrame.from_dict(uniqueValuesNumber,orient='index', columns=['Number of unique values']))\n",
    "\t\t#print(\"Discrete data frame:\\n\", discreteDf)\t\t\n",
    "\n",
    "\t# Algorithm\n",
    "\tscore = []\n",
    "\tcounter = 0\n",
    "\twhile counter < maxIteration and len(remainingFeatures) > 0:\n",
    "\t\t# initialize the best score and feature\n",
    "\t\tbestFeature = None\n",
    "\t\tbestScore = createFeatureScore(metrics)\n",
    "\t\t\n",
    "\t\tfor feature in remainingFeatures:\n",
    "\t\t\tfeatureScore = createFeatureScore(metrics)# Initialize the feature score with the right metrics order\n",
    "\t\t\t\n",
    "\t\t\t# compute the variance score\n",
    "\t\t\tif allowedMetrics[0] in metrics: \n",
    "\t\t\t\tfeatureScore[allowedMetrics[0]] = df[feature].var() \n",
    "\t\t\t# compute the correlation score\n",
    "\t\t\tif allowedMetrics[1] in metrics:\n",
    "\t\t\t\tfeatureScore[allowedMetrics[1]] = np.abs(df[feature].corr(df[target]))\n",
    "\t\t\t# compute the cfs score\n",
    "\t\t\tif allowedMetrics[2] in metrics:\n",
    "\t\t\t\tfeatureScore[allowedMetrics[2]] = cfs(df, selectedFeatures + [feature], target)\n",
    "\t\t\t# compute the mifs score\n",
    "\t\t\tif allowedMetrics[3] in metrics:\n",
    "\t\t\t\tfeatureScore[allowedMetrics[3]] = mifs(df, selectedFeatures, feature, target, beta=beta)\n",
    "\t\t\t\tif mifs_cache:\n",
    "\t\t\t\t\tmifs_caching_flush(path, entropyCache, jointEntropyCache, entropyFilename, jointEntropyFilename)\n",
    "\t\t\t\n",
    "\t\t\t# check if the score is better than the best score considering all the metrics with order of priority\n",
    "\t\t\tif compareFeatureScore(featureScore, bestScore, metrics):\n",
    "\t\t\t\tbestScore = featureScore\n",
    "\t\t\t\tbestFeature = feature\n",
    "\t\t\t\n",
    "\t\tselectedFeatures.append(bestFeature)\n",
    "\t\tremainingFeatures.remove(bestFeature)\n",
    "\t\tscore.append(bestScore)\n",
    "\t\tcounter += 1\n",
    "\t\n",
    "\treturn selectedFeatures, score, remainingFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9f461b561d2576",
   "metadata": {},
   "source": [
    "## Sequential Backward Selection (SBS)\n",
    "\n",
    "The SBS algorithm is a feature selection method that begins with the full set of attributes and iteratively removes attributes until only a selected subset of features remains. It is particularly effective when the optimal subset has a large number of attributes. The process starts with the entire feature set and gradually narrows it down by eliminating less important features.\n",
    "\n",
    "![SBS](images/SBS.PNG)\n",
    "\n",
    "## Implementation of the SBS Algorithm\n",
    "\n",
    "In the following implementation of the SBS algorithm, we start with the a set of remaining features and progressively reduce it through a series of iterations:\n",
    "\n",
    "1. Compute for each remaining feature the score of all remaining feature except the evaluated one\n",
    "2. Remove the feature with the lowest score.\n",
    "\n",
    "This process is repeated until the maximum number of iterations is reached or until there is one remaining feature\n",
    "\n",
    "### Evaluation Functions for Feature Score\n",
    "\n",
    "The score of each feature is determined using one of the following evaluation functions:\n",
    "\n",
    "- Variance\n",
    "- Correlation\n",
    "- Correlation Feature Selection (CFS)\n",
    "- Mutual Information Feature Selection (MIFS)\n",
    "\n",
    "If multiple evaluation functions are given to the function, the score is based on the metrics order of priority given by the order of the metrics in the metrics list, so if the first score is the same for two features, the second score is used to determine the best feature and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ab200f827a14a207",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:07:21.975635600Z",
     "start_time": "2024-02-18T23:07:21.670653500Z"
    }
   },
   "outputs": [],
   "source": [
    "def selection_sbs(df, remainingFeatures, target, metrics, maxIteration=np.inf, discreteDf=None, beta=0.5):\n",
    "\tmetrics = checkMetrics(metrics, allowedMetrics)\n",
    "\n",
    "\t# Create the discrete data frame if needed\n",
    "\tmifs_cache = discreteDf is not None\n",
    "\tif allowedMetrics[3] in metrics and discreteDf is None:\n",
    "\t\tprint(\"Warning: mifs cache not enabled\")\n",
    "\t\tdiscreteDf, uniqueValuesNumber, featuresBoundaries = chiMerge(df, df.columns[:-1].tolist(), df.columns[-1], max_intervals=100, min_intervals=2)\n",
    "\t\tdiscreteDf.to_csv(path + discreteDf_filename, index=False)\n",
    "\t\tglobal entropyCache, jointEntropyCache\n",
    "\t\tentropyCache, jointEntropyCache = {}, {} # Cleaning Cache\n",
    "\t\t\n",
    "\t\t#print(\"Features Boundaries:\\n\", featuresBoundaries)\n",
    "\t\t#print(\"Features unique values:\\n\", pd.DataFrame.from_dict(uniqueValuesNumber,orient='index', columns=['Number of unique values']))\n",
    "\t\t#print(\"Discrete data frame:\\n\", discreteDf)\n",
    "\t\n",
    "\t# Algorithm\n",
    "\tscore = []\n",
    "\teliminatedFeatures = []\n",
    "\tremainingFeatures = remainingFeatures.copy()\n",
    "\twhile len(eliminatedFeatures) < maxIteration and len(remainingFeatures) > 1:\n",
    "\t\t# initialize the best score and feature\n",
    "\t\tworstFeature = None\n",
    "\t\tworstScore = createFeatureScore(metrics, positiveValue=True)\n",
    "\t\t \n",
    "\t\tfor feature in remainingFeatures:\n",
    "\t\t\tfeatureScore = createFeatureScore(metrics) # Initialize the feature score with the right metrics order\n",
    "\t\t\t\n",
    "\t\t\t# Select all the features except the current feature\n",
    "\t\t\ttestFeatures = remainingFeatures.copy()\n",
    "\t\t\ttestFeatures.remove(feature)\n",
    "\t\t\t\n",
    "\t\t\tif allowedMetrics[0] in metrics:\n",
    "\t\t\t\tfeatureScore[allowedMetrics[0]] = df[feature].var()\n",
    "\t\t\tif allowedMetrics[1] in metrics:\n",
    "\t\t\t\tfeatureScore[allowedMetrics[1]] = np.abs(df[feature].corr(df[target]))\n",
    "\t\t\tif allowedMetrics[2] in metrics:\n",
    "\t\t\t\tfeatureScore[allowedMetrics[2]] = cfs(df, testFeatures, target)\n",
    "\t\t\tif allowedMetrics[3] in metrics:\n",
    "\t\t\t\tfeatureScore[allowedMetrics[3]] = mifs(df, testFeatures, feature, target, beta=beta)\n",
    "\t\t\t\tif mifs_cache:\n",
    "\t\t\t\t\tmifs_caching_flush(path, entropyCache, jointEntropyCache, entropyFilename, jointEntropyFilename)\n",
    "\t\t\t\n",
    "\t\t\t# check if the score is worse than the worst score considering all the metrics with order of priority\n",
    "\t\t\tif compareFeatureScore(worstScore, featureScore, metrics):\n",
    "\t\t\t\tworstScore = featureScore\n",
    "\t\t\t\tworstFeature = feature\n",
    "\t\t\t\t\n",
    "\t\tremainingFeatures.remove(worstFeature)\n",
    "\t\tscore.append(worstScore)\n",
    "\t\teliminatedFeatures.append(worstFeature)\t\t\n",
    "\t\n",
    "\treturn remainingFeatures, eliminatedFeatures, score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c16709d62e5b98",
   "metadata": {},
   "source": [
    "### Appling the SFS and SBS algorithms to the Breast Cancer Wisconsin (Diagnostic) Data Set\n",
    "\n",
    "1. Initialize the selected features list\n",
    "2. Initialize the remaining features list without the target\n",
    "3. Get target name\n",
    "4. Call the SFS function with maxIteration= 2\n",
    "5. Call the SBS function with maxIteration= 3\n",
    "6. Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7cfad075f19f7867",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:07:22.204849800Z",
     "start_time": "2024-02-18T23:07:21.864458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "\t-Feature: area3, Score: variance: 324167.385102\n",
      "\t-Feature: area1, Score: variance: 123843.554318\n",
      "--------------------------------------------------\n",
      "Eliminated features: \n",
      "\t-Feature: fractal_dimension2, Score: variance: 0.000007\n",
      "\t-Feature: smoothness2, Score: variance: 0.000009\n",
      "\t-Feature: concave_points2, Score: variance: 0.000038\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "target = df.columns[-1]\n",
    "\n",
    "selectedFeatures, score, remainingFeatures = selection_sfs(df, [], df.columns[:-1].tolist(), target,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   metrics=allowedMetrics[0], maxIteration=2)\n",
    "remainingFeatures, eliminatedFeatures, worstScore = selection_sbs(df, remainingFeatures, target,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  metrics=allowedMetrics[0], maxIteration= 3)\n",
    "\n",
    "#printScoreDetails(selectedFeatures, score, remainingFeatures)\n",
    "printFinalScore(selectedFeatures, score, eliminatedFeatures, worstScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18541a06726f2eb4",
   "metadata": {},
   "source": [
    "## Bidirectional Selection (BDS)\n",
    "\n",
    "The BDS algorithm is a search method that simultaneously explores the search space from both the initial state and the goal state. It is particularly effective in finding the shortest path between two states in a search graph. The process involves two simultaneous searches, one forward (SFS) from the initial state and one backward (SBS) from the goal state, with the goal of meeting in the middle.\n",
    "\n",
    "![BDS](images/BDS.PNG)\n",
    "\n",
    "## Implementation of the BDS Algorithm\n",
    "\n",
    "In the following implementation of the SFS algorithm, we begin with a set of features, which can be either empty or contain initial attributes, and a list of remaining features, which includes all features except those already selected and the target feature. The algorithm operates through a series of iterations:\n",
    "\n",
    "### Sequential Forward Selection (SFS):\n",
    "\n",
    "1. Compute the score of each remaining feature considering the selected features and the target feature.\n",
    "2. Select the feature with the best score.\n",
    "3. Add the selected feature to the list of selected features.\n",
    "4. Remove the selected feature from the list of remaining features.\n",
    "\n",
    "### Sequential Backward Selection (SBS):\n",
    "\n",
    "5. Compute for each remaining feature the score of all remaining features except the evaluated one.\n",
    "6. Remove the feature with the lowest score.\n",
    "\n",
    "This process is repeated until the maximum number of iterations is reached or until there are no more remaining features to select from. The goal of BDS is to minimize the search space by simultaneously exploring from both ends, reducing the time and resources needed to find a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "13b485cb77318432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:07:22.628404Z",
     "start_time": "2024-02-18T23:07:22.188696600Z"
    }
   },
   "outputs": [],
   "source": [
    "def selection_bds(df, selectedFeatures, remainingFeatures, target, metrics, maxIteration=1, discreteDf=None, beta=0.5):\n",
    "\tmetrics = checkMetrics(metrics, allowedMetrics)\n",
    "\t\n",
    "\tselectedFeaturesScore = []\n",
    "\teliminatedFeaturesWorstScore = []\n",
    "\teliminatedFeatures = []\n",
    "\n",
    "\twhile(len(selectedFeatures) < maxIteration and len(remainingFeatures) > 0):\n",
    "\t\tselectedFeatures, selectedFeatureScore, remainingFeatures = selection_sfs(df, selectedFeatures, remainingFeatures, target, metrics, maxIteration= 1, discreteDf=discreteDf, beta=beta)\n",
    "\t\tremainingFeatures, eliminatedFeature, eliminatedFeatureWorstScore = selection_sbs(df, remainingFeatures, target, metrics, maxIteration= 1, discreteDf=discreteDf, beta=beta)\n",
    "\n",
    "\t\tselectedFeaturesScore.extend(selectedFeatureScore)\n",
    "\t\tmaxIterationOverLoad = eliminatedFeature == []#It appends when |remainingFeatures| = 2\n",
    "\t\tif not maxIterationOverLoad:\n",
    "\t\t\teliminatedFeaturesWorstScore.extend(eliminatedFeatureWorstScore)\n",
    "\t\t\teliminatedFeatures.extend(eliminatedFeature)\n",
    "\t\t\n",
    "\treturn selectedFeatures, selectedFeaturesScore, remainingFeatures, eliminatedFeatures, eliminatedFeaturesWorstScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c840a490acd8391",
   "metadata": {},
   "source": [
    "### Bidirectional Selection with Variance as evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "69528fa5a0feb94f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:07:22.939208300Z",
     "start_time": "2024-02-18T23:07:22.576375200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "\t-Feature: area3, Score: variance: 324167.385102\n",
      "\t-Feature: area1, Score: variance: 123843.554318\n",
      "\t-Feature: area2, Score: variance: 2069.431583\n",
      "\t-Feature: perimeter3, Score: variance: 1129.130847\n",
      "\t-Feature: perimeter1, Score: variance: 590.440480\n",
      "--------------------------------------------------\n",
      "Eliminated features: \n",
      "\t-Feature: fractal_dimension2, Score: variance: 0.000007\n",
      "\t-Feature: smoothness2, Score: variance: 0.000009\n",
      "\t-Feature: concave_points2, Score: variance: 0.000038\n",
      "\t-Feature: fractal_dimension1, Score: variance: 0.000050\n",
      "\t-Feature: symmetry2, Score: variance: 0.000068\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "selectedFeatures, selectedFeaturesScore, remainingFeatures, eliminatedFeatures, eliminatedFeaturesWorstScore = selection_bds(df, [], df.columns[:-1].tolist(), target, metrics=allowedMetrics[0], maxIteration= 5)\n",
    "\n",
    "printFinalScore(selectedFeatures, selectedFeaturesScore, eliminatedFeatures, eliminatedFeaturesWorstScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c422f130b9521c2",
   "metadata": {},
   "source": [
    "### Bidirectional Selection with Correlation as evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ffb238e0c7f4c6fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:07:23.347463Z",
     "start_time": "2024-02-18T23:07:22.744848900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "\t-Feature: concave_points3, Score: correlation: 0.793566\n",
      "\t-Feature: perimeter3, Score: correlation: 0.782914\n",
      "\t-Feature: concave_points1, Score: correlation: 0.776614\n",
      "\t-Feature: radius3, Score: correlation: 0.776454\n",
      "\t-Feature: perimeter1, Score: correlation: 0.742636\n",
      "--------------------------------------------------\n",
      "Eliminated features: \n",
      "\t-Feature: symmetry2, Score: correlation: 0.006522\n",
      "\t-Feature: texture2, Score: correlation: 0.008303\n",
      "\t-Feature: fractal_dimension1, Score: correlation: 0.012838\n",
      "\t-Feature: smoothness2, Score: correlation: 0.067016\n",
      "\t-Feature: fractal_dimension2, Score: correlation: 0.077972\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "selectedFeatures, selectedFeaturesScore, remainingFeatures, eliminatedFeatures, eliminatedFeaturesWorstScore = selection_bds(df, [], df.columns[:-1].tolist(), target, metrics=allowedMetrics[1], maxIteration= 5)\n",
    "\n",
    "printFinalScore(selectedFeatures, selectedFeaturesScore, eliminatedFeatures, eliminatedFeaturesWorstScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576dc1b5a94d107e",
   "metadata": {},
   "source": [
    "### Bidirectional Selection with Correlation Feature Selection as evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5703b7ab02c4272d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:08:39.943623800Z",
     "start_time": "2024-02-18T23:07:23.052021900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "\t-Feature: concave_points3, Score: cfs: 0.793566\n",
      "\t-Feature: perimeter3, Score: cfs: 0.939393\n",
      "\t-Feature: concave_points1, Score: cfs: 0.927019\n",
      "\t-Feature: texture3, Score: cfs: 0.916520\n",
      "\t-Feature: area1, Score: cfs: 0.901798\n",
      "--------------------------------------------------\n",
      "Eliminated features: \n",
      "\t-Feature: radius3, Score: cfs: 0.720225\n",
      "\t-Feature: radius1, Score: cfs: 0.690256\n",
      "\t-Feature: perimeter1, Score: cfs: 0.655536\n",
      "\t-Feature: area3, Score: cfs: 0.615687\n",
      "\t-Feature: area2, Score: cfs: 0.566182\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "selectedFeatures, selectedFeaturesScore, remainingFeatures, eliminatedFeatures, eliminatedFeaturesWorstScore = selection_bds(df, [], df.columns[:-1].tolist(), target, metrics=allowedMetrics[2], maxIteration= 5)\n",
    "\n",
    "printFinalScore(selectedFeatures, selectedFeaturesScore, eliminatedFeatures, eliminatedFeaturesWorstScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37f76d58458460b",
   "metadata": {},
   "source": [
    "### Bidirectional Selection with Mutual Information Feature Selection as evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ed51765a25b1d2b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:08:44.120718500Z",
     "start_time": "2024-02-18T23:08:39.796808800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "\t-Feature: concave_points1, Score: mifs: 0.942090\n",
      "\t-Feature: radius3, Score: mifs: -3.389747\n",
      "\t-Feature: smoothness3, Score: mifs: -7.535603\n",
      "\t-Feature: symmetry1, Score: mifs: -11.611160\n",
      "\t-Feature: radius1, Score: mifs: -15.751313\n",
      "--------------------------------------------------\n",
      "Eliminated features: \n",
      "\t-Feature: smoothness2, Score: mifs: -122.902964\n",
      "\t-Feature: fractal_dimension2, Score: mifs: -114.013164\n",
      "\t-Feature: area3, Score: mifs: -105.234858\n",
      "\t-Feature: compactness2, Score: mifs: -96.337898\n",
      "\t-Feature: radius2, Score: mifs: -87.517516\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "selectedFeatures, selectedFeaturesScore, remainingFeatures, eliminatedFeatures, eliminatedFeaturesWorstScore = selection_bds(df, [], df.columns[:-1].tolist(), target, metrics=allowedMetrics[3], maxIteration= 5, discreteDf=discreteDf)\n",
    "\n",
    "printFinalScore(selectedFeatures, selectedFeaturesScore, eliminatedFeatures, eliminatedFeaturesWorstScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28241c717261e9b",
   "metadata": {},
   "source": [
    "## Plus-l-Minus-r Selection (LRS)\n",
    "\n",
    "The Plus-l-Minus-r Selection method is like the Bidirectional Selection (BDS) algorithm, but it allows the forward and backward searches to be performed with different step sizes.The l parameter controls the number of features added in each iteration of the forward search (SFS), while the r parameter controls the number of features removed in each iteration of the backward search (SBS). \n",
    "\n",
    "![Plus-l-Minus-r Selection](images/LRS.PNG)\n",
    "\n",
    "### Implementation of the Plus-l-Minus-r Selection Algorithm\n",
    "\n",
    "In the following implementation of the Plus-l-Minus-r Selection algorithm, we begin with a set of features. This set can initially be empty or contain the starting attributes. We also maintain a list of remaining features, which includes all features except those already selected and the target feature. The algorithm operates through a series of iterations:\n",
    "\n",
    "#### Sequential Forward Selection (SFS):\n",
    "\n",
    "1. Calculate the score for each remaining feature, considering the selected features and the target feature.\n",
    "2. Choose the feature with the highest score.\n",
    "3. Add the selected feature to the list of chosen features.\n",
    "4. Remove the selected feature from the list of remaining features.\n",
    "5. Repeat steps 1-4 until l features have been selected.\n",
    "\n",
    "#### Sequential Backward Selection (SBS):\n",
    "\n",
    "6. Calculate the score for each remaining feature, considering all remaining features except the one being evaluated.\n",
    "7. Remove the feature with the lowest score.\n",
    "8. Repeat steps 6-7 until r features have been removed.\n",
    "\n",
    "This process is repeated until the maximum number of iterations is reached or until there are no more remaining features to select from. The goal of Plus-l-Minus-r Selection is to minimize the search space by simultaneously exploring from both ends, reducing the time and resources needed to find a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "70bf25255ebfbb09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:08:44.423311900Z",
     "start_time": "2024-02-18T23:08:44.143555Z"
    }
   },
   "outputs": [],
   "source": [
    "# Implementation of the LRS algorithm using the SFS and SBS function\n",
    "def selection_lrs(df, selectedFeatures, remainingFeatures, target, metrics, l=1, r=1, maxIteration=1, discreteDf=None, beta=0.5):\n",
    "\tmetrics = checkMetrics(metrics, allowedMetrics)\n",
    "\t\n",
    "\tselectedFeaturesScore = []\n",
    "\teliminatedFeaturesWorstScore = []\n",
    "\teliminatedFeatures = []\n",
    "\n",
    "\twhile(len(selectedFeatures) < maxIteration and len(remainingFeatures) > 0):\n",
    "\t\tselectedFeatures, selectedFeatureScore, remainingFeatures = selection_sfs(df, selectedFeatures, remainingFeatures, target, metrics, maxIteration= l, discreteDf=discreteDf, beta=beta)\n",
    "\t\tremainingFeatures, eliminatedFeature, eliminatedFeatureWorstScore = selection_sbs(df, remainingFeatures, target, metrics, maxIteration= r, discreteDf=discreteDf, beta=beta)\n",
    "\n",
    "\t\tselectedFeaturesScore.extend(selectedFeatureScore)\n",
    "\t\tmaxIterationOverLoad = eliminatedFeature == []#It appends when |remainingFeatures| = 2\n",
    "\t\tif not maxIterationOverLoad:\n",
    "\t\t\teliminatedFeaturesWorstScore.extend(eliminatedFeatureWorstScore)\n",
    "\t\t\teliminatedFeatures.extend(eliminatedFeature)\n",
    "\t\n",
    "\treturn selectedFeatures, selectedFeaturesScore, remainingFeatures, eliminatedFeatures, eliminatedFeaturesWorstScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3d34e1118f2904",
   "metadata": {},
   "source": [
    "## Plus-l-Minus-r Selection with Variance as evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d279c868b5458b6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:08:44.557082900Z",
     "start_time": "2024-02-18T23:08:44.183604100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "\t-Feature: area3, Score: variance: 324167.385102\n",
      "\t-Feature: area1, Score: variance: 123843.554318\n",
      "\t-Feature: area2, Score: variance: 2069.431583\n",
      "\t-Feature: perimeter3, Score: variance: 1129.130847\n",
      "\t-Feature: perimeter1, Score: variance: 590.440480\n",
      "\t-Feature: texture3, Score: variance: 37.776483\n",
      "--------------------------------------------------\n",
      "Eliminated features: \n",
      "\t-Feature: fractal_dimension2, Score: variance: 0.000007\n",
      "\t-Feature: smoothness2, Score: variance: 0.000009\n",
      "\t-Feature: concave_points2, Score: variance: 0.000038\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "selectedFeatures, selectedFeaturesScore, remainingFeatures, eliminatedFeatures, eliminatedFeaturesWorstScore = selection_lrs(df, [], df.columns[:-1].tolist(), df.columns[-1], metrics=allowedMetrics[0], maxIteration= 5, l=2, r=1)\n",
    "\n",
    "printFinalScore(selectedFeatures, selectedFeaturesScore, eliminatedFeatures, eliminatedFeaturesWorstScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac639e6f8a0b613",
   "metadata": {},
   "source": [
    "## Plus-l-Minus-r Selection with Correlation as evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c256075bc2d9b062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:08:44.973814700Z",
     "start_time": "2024-02-18T23:08:44.295762200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "\t-Feature: concave_points3, Score: correlation: 0.793566\n",
      "\t-Feature: perimeter3, Score: correlation: 0.782914\n",
      "\t-Feature: concave_points1, Score: correlation: 0.776614\n",
      "\t-Feature: radius3, Score: correlation: 0.776454\n",
      "\t-Feature: perimeter1, Score: correlation: 0.742636\n",
      "\t-Feature: area3, Score: correlation: 0.733825\n",
      "--------------------------------------------------\n",
      "Eliminated features: \n",
      "\t-Feature: symmetry2, Score: correlation: 0.006522\n",
      "\t-Feature: texture2, Score: correlation: 0.008303\n",
      "\t-Feature: fractal_dimension1, Score: correlation: 0.012838\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "selectedFeatures, selectedFeaturesScore, remainingFeatures, eliminatedFeatures, eliminatedFeaturesWorstScore = selection_lrs(df, [], df.columns[:-1].tolist(), df.columns[-1], metrics=allowedMetrics[1], maxIteration= 5, l=2, r=1)\n",
    "\n",
    "printFinalScore(selectedFeatures, selectedFeaturesScore, eliminatedFeatures, eliminatedFeaturesWorstScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761301d334a243f8",
   "metadata": {},
   "source": [
    "## Plus-l-Minus-r Selection with Correlation Feature Selection as evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b2a815ef87e33c0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:09:31.895549400Z",
     "start_time": "2024-02-18T23:08:44.719848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "\t-Feature: concave_points3, Score: cfs: 0.793566\n",
      "\t-Feature: radius3, Score: cfs: 0.940381\n",
      "\t-Feature: concave_points1, Score: cfs: 0.929731\n",
      "\t-Feature: texture3, Score: cfs: 0.918798\n",
      "\t-Feature: perimeter1, Score: cfs: 0.906712\n",
      "\t-Feature: symmetry3, Score: cfs: 0.901998\n",
      "--------------------------------------------------\n",
      "Eliminated features: \n",
      "\t-Feature: perimeter3, Score: cfs: 0.706102\n",
      "\t-Feature: radius1, Score: cfs: 0.663781\n",
      "\t-Feature: area3, Score: cfs: 0.607910\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "selectedFeatures, selectedFeaturesScore, remainingFeatures, eliminatedFeatures, eliminatedFeaturesWorstScore = selection_lrs(df, [], df.columns[:-1].tolist(), df.columns[-1], metrics=allowedMetrics[2], maxIteration= 5, l=2, r=1)\n",
    "\n",
    "printFinalScore(selectedFeatures, selectedFeaturesScore, eliminatedFeatures, eliminatedFeaturesWorstScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba579e83f4c8674",
   "metadata": {},
   "source": [
    "## Plus-l-Minus-r Selection with Mutual Information Feature Selection as evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f014f2c3c09f08ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T23:09:35.778501Z",
     "start_time": "2024-02-18T23:09:31.830637500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "\t-Feature: concave_points1, Score: mifs: 0.942090\n",
      "\t-Feature: radius3, Score: mifs: -3.389747\n",
      "\t-Feature: smoothness3, Score: mifs: -7.535603\n",
      "\t-Feature: symmetry1, Score: mifs: -11.611160\n",
      "\t-Feature: radius1, Score: mifs: -15.751313\n",
      "\t-Feature: smoothness1, Score: mifs: -20.109128\n",
      "--------------------------------------------------\n",
      "Eliminated features: \n",
      "\t-Feature: smoothness2, Score: mifs: -118.582277\n",
      "\t-Feature: fractal_dimension2, Score: mifs: -105.514830\n",
      "\t-Feature: area3, Score: mifs: -92.298051\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "selectedFeatures, selectedFeaturesScore, remainingFeatures, eliminatedFeatures, eliminatedFeaturesWorstScore = selection_lrs(df, [], df.columns[:-1].tolist(), df.columns[-1], metrics=allowedMetrics[3], maxIteration= 5, discreteDf=discreteDf, l=2, r=1)\n",
    "\n",
    "printFinalScore(selectedFeatures, selectedFeaturesScore, eliminatedFeatures, eliminatedFeaturesWorstScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb9b7d879effe0b",
   "metadata": {},
   "source": [
    "## Sequential Forward Floating Selection (SFFS)\n",
    "\n",
    "The Sequential Forward Floating Selection (SFFS) method is a feature selection technique that combines elements of forward selection and backward elimination. SFFS aims to find an optimal subset of features by iteratively adding and removing features based on their performance scores.\n",
    "\n",
    "![SFFS](images/SFFS.PNG)\n",
    "\n",
    "### Implementation of the Sequential Forward Floating Selection Algorithm\n",
    "\n",
    "In the following implementation of the SFFS algorithm, we start with an empty set of selected features and a list of all available features. The algorithm operates through a series of iterations:\n",
    "\n",
    "1. **Sequential Forward Selection (SFS):**\n",
    "   1. Calculate the performance score for each remaining feature, considering the selected features.\n",
    "   2. Choose the feature with the highest score.\n",
    "   3. Add the selected feature to the list of chosen features.\n",
    "   4. Remove the selected feature from the list of remaining features.\n",
    "   \n",
    "2. **Sequential Backward Floating Selection (SBFS):**\n",
    "   5. Calculate the performance score for each feature in the selected set while excluding the one being evaluated.\n",
    "   6. Identify the feature with the lowest score among the selected features.\n",
    "   7. Remove the feature with the lowest score if removing it improves the overall performance score.\n",
    "   8. Repeat these steps until no further improvement can be achieved.\n",
    "   \n",
    "3. **Repeat SFS and SBFS Iterations:**\n",
    "   9. Continue alternating between SFS and SBFS iterations until a stopping criterion is met, such as a maximum number of features or convergence in performance score.\n",
    "\n",
    "The goal of SFFS is to gradually build a feature subset that optimizes a specific evaluation criterion while allowing for the removal of previously selected features if it benefits the overall performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
